{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyWK1FDmMX6z",
        "outputId": "50871b54-1b6e-497b-8254-1e904ac02130"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "ACTIVITY_SEVERITY = {\n",
        "    \"Browser window swapped\": 60,\n",
        "    \"Candidate iris looking left\": 15,\n",
        "    \"Candidate iris looking right\": 15,\n",
        "    \"Candidate looking down\": 30,\n",
        "    \"Candidate looking left\": 20,\n",
        "    \"Candidate looking right\": 20,\n",
        "    \"Candidate looking up\": 20,\n",
        "    \"Cell phone detected\": 90,\n",
        "    \"Copy\": 10,\n",
        "    \"Cut\": 15,\n",
        "    \"Display change detected\": 60,\n",
        "    \"Laptop detected\": 95,\n",
        "    \"No face detected\": 90,\n",
        "    \"Paste\": 10,\n",
        "    \"Tab change detected\": 75,\n",
        "    \"Window change detected\": 65,\n",
        "    \"Window focus changed\": 70\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "CRITICAL_ACTIVITIES = [\"Cell phone detected\", \"Laptop detected\", \"No face detected\"]\n",
        "\n",
        "def convert_timestamp(ts_str):\n",
        "    try:\n",
        "        if \"NaN\" in ts_str:\n",
        "            return None\n",
        "        h, m, s = ts_str.split(\":\")\n",
        "        return int(h)*3600 + int(m)*60 + float(s)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def get_time_bin(seconds, bin_size=300, max_bins=50):\n",
        "    if seconds is None:\n",
        "        return None\n",
        "    idx = int(seconds // bin_size)\n",
        "    return min(idx, max_bins - 1)\n",
        "\n",
        "def load_json_data(path):\n",
        "    try:\n",
        "        with open(path) as f:\n",
        "            return json.load(f)\n",
        "    except:\n",
        "        return {\"activityLog\": []}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_features_with_moderate_duplication(data, num_bins=50):\n",
        "    counts = {a: np.zeros(num_bins) for a in ACTIVITY_SEVERITY}\n",
        "    weights = {a: np.zeros(num_bins) for a in ACTIVITY_SEVERITY}\n",
        "    critical = []\n",
        "    last_swap = -1.0\n",
        "    ccp_times = []\n",
        "\n",
        "    for e in data.get(\"activityLog\", []):\n",
        "        ts = e.get(\"timestampInVideo\", \"\")\n",
        "        if \"NaN\" in ts:\n",
        "            continue\n",
        "        sec = convert_timestamp(ts)\n",
        "        if sec is None:\n",
        "            continue\n",
        "        b = get_time_bin(sec, max_bins=num_bins)\n",
        "        if b is None or b >= num_bins:\n",
        "            continue\n",
        "\n",
        "        act = e.get(\"activityDescription\", \"\")\n",
        "        cnt = e.get(\"count\", 1)\n",
        "\n",
        "        if act == \"Browser window swapped\":\n",
        "            last_swap = max(last_swap, sec)\n",
        "        if act in {\"Copy\", \"Cut\", \"Paste\"}:\n",
        "            ccp_times.append(sec)\n",
        "\n",
        "        if act in ACTIVITY_SEVERITY:\n",
        "            counts[act][b] += cnt\n",
        "            sev = ACTIVITY_SEVERITY[act]\n",
        "            dup = 1 + sev/15\n",
        "            weights[act][b] += cnt * dup\n",
        "            if act in CRITICAL_ACTIVITIES:\n",
        "                critical.append((sec, sev))\n",
        "\n",
        "    feats = []\n",
        "    # per‐activity bins + summaries\n",
        "    for act in ACTIVITY_SEVERITY:\n",
        "        c = counts[act]\n",
        "        w = weights[act]\n",
        "        feats.extend(c)\n",
        "        feats.extend(w)\n",
        "        feats.append(w.sum())\n",
        "        feats.append(w.max())\n",
        "        feats.append((w>0).sum()/num_bins)\n",
        "\n",
        "    # critical summaries\n",
        "    for act in CRITICAL_ACTIVITIES:\n",
        "        w = weights[act]\n",
        "        feats.append(w.sum())\n",
        "        feats.append(w.max())\n",
        "        feats.append((w>0).sum()/num_bins)\n",
        "\n",
        "    # first/last critical\n",
        "    if critical:\n",
        "        times, sevs = zip(*critical)\n",
        "        feats.append(min(times)/3600)\n",
        "        feats.append(min(sevs))\n",
        "        feats.append(max(times)/3600)\n",
        "    else:\n",
        "        feats.extend([0,0,0])\n",
        "\n",
        "    # global stats\n",
        "    all_w = np.sum(np.vstack(list(weights.values())), axis=0)\n",
        "    feats.append(all_w.sum())\n",
        "    feats.append(all_w.max())\n",
        "    feats.append(all_w.std())\n",
        "\n",
        "    # flags\n",
        "    has = lambda a: int(counts[a].sum()>0) * ACTIVITY_SEVERITY[a]\n",
        "    feats.append(has(\"Laptop detected\"))\n",
        "    feats.append(has(\"Cell phone detected\"))\n",
        "    feats.append(has(\"No face detected\"))\n",
        "\n",
        "    # new: mid‐exam (5–55 min) count\n",
        "    sb = get_time_bin(300, max_bins=num_bins)\n",
        "    eb = get_time_bin(3300, max_bins=num_bins)\n",
        "    mid_count = sum(counts[a][sb:eb+1].sum() for a in ACTIVITY_SEVERITY)\n",
        "    feats.append(mid_count)\n",
        "\n",
        "    # new: CCP after last swap\n",
        "    feats.append(sum(1 for t in ccp_times if t>last_swap))\n",
        "\n",
        "    return np.array(feats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def build_ensemble_model(features, train_idx, n_models=5):\n",
        "    X = np.vstack([features[i] for i in train_idx if i < len(features)])\n",
        "    scaler = RobustScaler().fit(X)\n",
        "    Xs = scaler.transform(X)\n",
        "    models = []\n",
        "    for i in range(n_models):\n",
        "        m = IsolationForest(\n",
        "            n_estimators=500,\n",
        "            max_samples=0.5,\n",
        "            contamination=0.05,\n",
        "            max_features=0.8,\n",
        "            bootstrap=True,\n",
        "            random_state=42 + i,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        m.fit(Xs)\n",
        "        models.append(m)\n",
        "    return models, scaler\n",
        "\n",
        "def adjust_anomaly_scores(raw, feats, valid):\n",
        "    adjusted = []\n",
        "    for i, r in enumerate(raw):\n",
        "        base = int(max(0, 100*(1 - (r+1)/2) - 10))\n",
        "        lap = feats[i][-5]\n",
        "        pho = feats[i][-4]\n",
        "        nof = feats[i][-3]\n",
        "        mid = feats[i][-2]\n",
        "        post = feats[i][-1]\n",
        "\n",
        "        if lap>0: base = max(base, 83)\n",
        "        if lap>1: base = max(base, 95)\n",
        "        if pho>0: base = max(base, 82)\n",
        "        if pho>1: base = max(base, 93)\n",
        "        if mid > 100: base = max(base, 70)\n",
        "        \n",
        "       \n",
        "        adjusted.append(min(100, max(0, base)))\n",
        "    return adjusted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    np.random.seed(69)\n",
        "    all_feats = []\n",
        "    valid = []\n",
        "    for i in range(1,51):\n",
        "        fn = f\"candidate{i}.json\"\n",
        "        if os.path.exists(fn):\n",
        "            data = load_json_data(fn)\n",
        "            all_feats.append(create_features_with_moderate_duplication(data))\n",
        "            valid.append(i)\n",
        "        else:\n",
        "            # empty feature vector fallback\n",
        "            if all_feats:\n",
        "                all_feats.append(np.zeros_like(all_feats[0]))\n",
        "            valid.append(i)\n",
        "\n",
        "    if not all_feats:\n",
        "        print(\"No data.\")\n",
        "        return\n",
        "\n",
        "    all_feats = np.array(all_feats)\n",
        "    idx = np.arange(len(valid))\n",
        "    np.random.shuffle(idx)\n",
        "    train = idx[:min(35, len(idx))]\n",
        "\n",
        "    models, scaler = build_ensemble_model(all_feats, train, n_models=5)\n",
        "    Xs = scaler.transform(all_feats)\n",
        "\n",
        "  \n",
        "    decs = np.vstack([m.decision_function(Xs) for m in models])\n",
        "    raw_scores = decs.mean(axis=0)\n",
        " \n",
        "    raw_scores += np.random.normal(loc=0, scale=0.03, size=raw_scores.shape)\n",
        "\n",
        "    final = adjust_anomaly_scores(raw_scores, all_feats, valid)\n",
        "    out = []\n",
        "    for i, cid in enumerate(valid):\n",
        "        out.append({\"id\": cid, \"score\": final[i]})\n",
        "        print(f\"{cid} scored {final[i]}\")\n",
        "\n",
        "    with open(\"ml_based_proctoring.json\",\"w\") as f:\n",
        "        json.dump(out, f, indent=2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
